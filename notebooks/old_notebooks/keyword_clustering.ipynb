{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import Counter\n",
    "import string\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pke\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from config import Config\n",
    "from risk_detection.utils import window\n",
    "from risk_detection.preprocessing.report_parser import report_info_from_risk_path\n",
    "from risk_detection.analysis.keyword_extraction import Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(Config.text_rank_keywords_dir(), '1750')\n",
    "keywords = dict()\n",
    "for keyword_file in glob.glob(os.path.join(path, '*.txt')):\n",
    "    with open(keyword_file, 'r') as keyword_f:\n",
    "        keys = keyword_f.read().split('\\n')\n",
    "    keywords[keyword_file] = Keywords(keys, report_info_from_risk_path(Path(keyword_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([CIK: 36047, Start Date: 2005-12-31 00:00:00, End Date: 2006-03-16 00:00:00, Filing Type: 10-K, File Name: 0001193125-06-056887.txt, CIK: 36047, Start Date: 2006-12-31 00:00:00, End Date: 2007-03-01 00:00:00, Filing Type: 10-K, File Name: 0001193125-07-043486.txt, CIK: 36047, Start Date: 2007-12-31 00:00:00, End Date: 2008-02-29 00:00:00, Filing Type: 10-K, File Name: 0001193125-08-043818.txt, CIK: 36047, Start Date: 2008-12-31 00:00:00, End Date: 2009-03-02 00:00:00, Filing Type: 10-K, File Name: 0001193125-09-042644.txt, CIK: 36047, Start Date: 2009-12-31 00:00:00, End Date: 2010-03-01 00:00:00, Filing Type: 10-K, File Name: 0001193125-10-044803.txt, CIK: 36047, Start Date: 2010-12-31 00:00:00, End Date: 2011-03-14 00:00:00, Filing Type: 10-K, File Name: 0001140361-11-016415.txt])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = keywords['c:\\\\machine_learning\\\\10k-emerging-risk-detection\\\\models\\\\keywords\\\\text_rank\\\\1750\\\\2006-05-31_2006-07-17_0001104659-06-047248.txt']\n",
    "next_keys = keywords['c:\\\\machine_learning\\\\10k-emerging-risk-detection\\\\models\\\\keywords\\\\text_rank\\\\1750\\\\2007-05-31_2007-07-20_0001104659-07-055173.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup_c, curr = keys.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup_n, next_cl = next_keys.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('significant', 90),\n",
       " ('significant capital', 86),\n",
       " ('significant decline', 86),\n",
       " ('regulatory standards', 86),\n",
       " ('significant government regulation', 79)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract('significant adverse regulatory', lookup_n.keys())#, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ReportInfo' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-f54b4954c1f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_cluster_nums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprev_closest_cluster_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcommon_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprev_closest_cluster_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon_words\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprev_closest_cluster_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcluster_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_closest_cluster_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ReportInfo' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "matches = dict()\n",
    "\n",
    "for cluster_num, cluster_words in next_cl.items():\n",
    "    next_cluster_nums = list()\n",
    "    for word in cluster_words:\n",
    "        words = process.extract(word, lookup_c.keys(), limit=5)\n",
    "        next_cluster_nums.extend([lookup_c[w[0]] for w in words])\n",
    "    \n",
    "    counts = Counter(next_cluster_nums)\n",
    "    prev_closest_cluster_num = counts.most_common()[0][0]\n",
    "    common_words = set(cluster_words).intersection(set(curr[prev_closest_cluster_num]))\n",
    "    if len(common_words) >= (min(len(cluster_words), len(curr[prev_closest_cluster_num])) // 2):\n",
    "        matches[cluster_num] = prev_closest_cluster_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 5, 6, 8, 19}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(next_cl.keys()) - set(matches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new a400 m military transport aircraft', 'a400 m cargo']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cl[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_keyword(keyword):\n",
    "    tokens_to_remove = set(('other', 'others', 'such', 'certain'))\n",
    "    \n",
    "    without_puncts = keyword.translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "    tokens = word_tokenize(without_puncts)\n",
    "    tags = pos_tag(tokens)\n",
    "    first_word, first_tag = tags[0]\n",
    "    last_word, last_tag = tags[-1]\n",
    "    \n",
    "    if first_tag == 'JJ' and first_word in tokens_to_remove:\n",
    "        tags = tags[1:]\n",
    "    if last_tag == 'JJ' and last_word in tokens_to_remove:\n",
    "        tags = tags[:-1]\n",
    "    \n",
    "    return ' '.join(tk for tk, _ in tags) if tags else ''\n",
    "\n",
    "\n",
    "def simple_clean_keyword(keyword):\n",
    "    tokens_to_remove = set(('other', 'others', 'such', 'certain'))\n",
    "    \n",
    "    without_puncts = keyword.translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "    tokens = word_tokenize(without_puncts)\n",
    "    first_word = tokens[0]\n",
    "    last_word = tokens[-1]\n",
    "    \n",
    "    if first_word in tokens_to_remove:\n",
    "        tokens = tokens[1:]\n",
    "    if last_word in tokens_to_remove:\n",
    "        tokens = tokens[:-1]\n",
    "    \n",
    "    return ' '.join(tokens) if tokens else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(Config.text_rank_keywords_dir(), '36047')\n",
    "keywords = dict()\n",
    "for keyword_file in tqdm(glob.glob(os.path.join(path, '*.txt'))):\n",
    "    with open(keyword_file, 'r') as keyword_f:\n",
    "        keys = keyword_f.read()\n",
    "        if not keys:\n",
    "            continue\n",
    "        keys = keys.split('\\n')\n",
    "    \n",
    "    cleaned_keywords = list()\n",
    "    for k in keys:\n",
    "        cl = simple_clean_keyword(k)\n",
    "        if cl:\n",
    "            cleaned_keywords.append(k)\n",
    "    \n",
    "    report_info = report_info_from_risk_path(Path(keyword_file))\n",
    "    keywords[report_info] = Keywords(cleaned_keywords, report_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2006-12-31 00:00:00\n",
      "{0: ['estate settlement services', 'estate settlement procedures act', 'potential litigation', 'mortgage interest rates', 'mortgage fund supply', 'significant legal', 'estate transactions', 'litigation expense', 'loss rates'], 2: ['historical stock option', 'shareholder derivative actions', 'basis point change', 'policy years', 'actual claims experience', 'duration contracts', 'historical experience', 'ibnr reserve'], 4: ['various states', 'similar state laws', 'various jurisdictions', 'states', 'operating subsidiaries'], 5: ['significant financial resources', 'substantial time', 'a higher percentage', 'long duration nature', 'more favorable terms', 'more favorable pricing', 'a reliable indicator', 'a substantial', 'substantial damages', 'higher prices', 'significant resources', 'higher degrees'], 6: ['a material adverse effect', 'unfavorable outcome following', 'a negative impact', 'adverse publicity'], 8: ['a revenue basis', 'a material change', 'market conduct', 'decreased revenue consumers', 'a material', 'market prices'], 10: ['a smaller base', 'limited human processing', 'lower cost labor', 'few years'], 11: ['such preferred stock', 'series a junior participating preferred shares', 'stock option practices', 'preferred stock', 'stock option'], 12: ['anticipated potential benefits', 'future operations', 'future performance', 'potential changes'], 15: ['insurance subsidiaries first', 'insurance services', 'insurance policy', 'insurance rates', 'insurance subsidiaries', 'insurance'], 16: ['first few years following', 'first years']}\n",
      "\n",
      "Year: 2007-12-31 00:00:00\n",
      "{0: ['other non - public entities', 'other third party consents', 'non - public entities', 'applicable regulatory', 'local regulatory', 'actual claims experience'], 1: ['long - duration contracts', 'substantial time', 'long duration nature', 'significant time', 'limited human processing', 'lower cost labor', 'substantial portion'], 3: ['estate settlement services industry', 'estate settlement services', 'estate settlement procedures', 'estate market', 'estate industry', 'estate', 'potential litigation'], 6: ['such preferred', 'such takeover', 'certain title', 'future operations', 'market conduct', 'anticipated level', 'future performance', 'anticipated potential'], 7: ['major rating agencies rates', 'mortgage interest rates', 'operating revenue', 'revenue basis', 'rating agencies', 'loss rates'], 8: ['other businesses', 'financial services businesses', 'foreign countries such', 'foreign governmental agencies'], 11: ['state level', 'similar state', 'states -'], 12: ['title insurance services', 'title claims title insurance', 'title insurance policy', 'title insurance rates', 'title insurance operations', 'title insurance'], 15: ['unexpected corporate overhead costs', 'material adverse effect', 'further shareholder action', 'material change', 'large groups'], 16: ['conduct such operations', 'public company', 'operating results', 'operating subsidiaries', 'operating performance']}\n",
      "\n",
      "Year: 2008-12-31 00:00:00\n",
      "{0: ['such losses', 'following risk factors', 'further shareholder action', 'potential customers', 'potential litigation', 'corresponding loss rates', 'following factors'], 1: ['real estate market', 'major ratings agencies rates', 'mortgage interest rates', 'governmental agencies', 'real estate'], 2: ['federal deposit insurance corporation coverage', 'foreign countries such', 'foreign governmental agencies', 'federal savings', 'various federal', 'federal laws'], 8: ['other third party consents', 'real estate settlement services', 'real estate settlement procedures', 'settlement service providers'], 10: ['current parent company', 'separate public company', 'company recent', 'company', 'operating subsidiaries'], 11: ['current unfavorable economic conditions', 'material adverse effect', 'general economic conditions', 'difficult operating environment', 'economic conditions'], 12: ['statutory assets', 'statutory guidelines', 'statutory liabilities', 'statutory surplus'], 16: ['company deposits substantial funds', 'company deposits funds', 'cash generating ability']}\n",
      "\n",
      "Year: 2009-12-31 00:00:00\n",
      "{0: ['other third party consents', 'conduct such operations many', 'conduct such operations', 'risks other', 'such transaction', 'company many', 'cash generating ability'], 1: ['certain financial', 'company deposits substantial funds', 'such preferred stock', 'certain economic', 'position certain', 'company deposits funds', 'public company'], 3: ['such losses', 'services system interruptions', 'general economic conditions', 'unfavorable economic conditions'], 7: ['substantial goodwill', 'more favorable terms', 'more favorable pricing', 'long duration nature'], 9: ['commercial real estate market', 'commercial real estate transactions', 'commercial real estate'], 10: ['market conduct', 'significant time', 'substantial investment', 'market conditions', 'further shareholder action', 'market values']}\n",
      "\n",
      "Year: 2010-12-31 00:00:00\n",
      "{0: ['certain internal transactions', 'various other federal', 'foreign countries such', 'local anti - corruption laws', 'suitable alternative data suppliers', '- proprietary databases'], 1: ['other regulatory penalties', 'such customers', 'substantial financial penalties', 'such restrictions', 'such litigation', 'such impairment', 'such liabilities', 'such disruptions', 'such interruptions', 'such individuals', 'such actions', 'substantial regulatory penalties'], 2: ['certain transition services agreements', 'certain services', 'certain significant', 'such security', '- related services', 'certain rights', 'such operations', 'certain operations', 'certain benefits'], 3: ['tax services business', 'financial services business', 'financial services businesses', 'financial services companies', '- business', 'business -'], 4: ['significant u.s. federal income tax liabilities', 'u.s. federal income tax requirements', 'significant tax liabilities', 'u.s. federal income tax', 'tax periods prior', 'tax sharing agreement', 'additional tax', 'applicable tax', 'tax liabilities', 'tax liability'], 5: ['other contractual restrictions', 'other corporate liabilities', 'other corporate opportunities', 'other interested parties', 'other unfavorable effects', 'other businesses', 'other agreements', 'other companies', 'other expenses', 'other products', 'other disposition', 'other situations'], 6: ['- public personal information', 'such letter', 'such disposition', 'certain personal', 'subsidiary first american title insurance company', '- frank act'], 7: ['third parties such', 'other third parties', 'third - party software', 'third - party suppliers'], 8: ['information services segment', 'information solutions business', 'information solutions group'], 9: ['tax - free transaction', 'tax - free treatment', 'tax - free'], 10: ['consumer financial protection', '- consumer electronic', 'sensitive consumer data', 'consumer credit market'], 11: ['consolidated tax', 'consolidated financial', 'pro - rata distribution', '- distribution actions'], 12: ['certain income tax liabilities', 'certain financial', 'certain data', 'certain transactions', 'certain subordinated debt', 'certain liabilities', 'certain investments', 'certain situations'], 13: ['financial information', 'federal financial institution regulators', 'mortgage origination services', 'financial markets regulation', 'financial restrictions', 'financial loss', 'significant equity transactions'], 14: ['such party', 'other party', '- defaulting party']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_cluster_matches(word_prev_cluster, prev_clusters, word_cluster, curr_clusters):\n",
    "    matches = dict()\n",
    "\n",
    "    for cluster_num, cluster_words in curr_clusters.items():\n",
    "        prev_cluster_nums = list()\n",
    "        for word in cluster_words:\n",
    "            words = process.extract(word, word_prev_cluster.keys(), limit=5)\n",
    "            prev_cluster_nums.extend([word_prev_cluster[w[0]] for w in words])\n",
    "\n",
    "        counts = Counter(prev_cluster_nums)\n",
    "        # Check if we have a perfect match\n",
    "        for prev_cluster_num, _ in counts.most_common():\n",
    "            if set(cluster_words) == set(prev_clusters[prev_cluster_num]):\n",
    "                matches[cluster_num] = prev_cluster_num\n",
    "                continue\n",
    "        \n",
    "        prev_closest_cluster_num = counts.most_common()[0][0]\n",
    "        common_words = set(cluster_words).intersection(set(prev_clusters[prev_closest_cluster_num]))\n",
    "        if len(common_words) >= (min(len(cluster_words), len(prev_clusters[prev_closest_cluster_num])) // 2):\n",
    "            matches[cluster_num] = prev_closest_cluster_num\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "for prev_k, curr_k in window(sorted(keywords.keys(), key=lambda rep: rep.start_date), 2):\n",
    "    print(f'Year: {curr_k.start_date}')\n",
    "    prev = keywords[prev_k]\n",
    "    curr = keywords[curr_k]\n",
    "    word_prev_cluster, prev_clusters = prev.cluster()\n",
    "    word_cluster, curr_clusters = curr.cluster()\n",
    "    \n",
    "    matches = find_cluster_matches(word_prev_cluster, prev_clusters, word_cluster, curr_clusters)\n",
    "    unmatched_clusters = curr_clusters.keys() - matches.keys()\n",
    "    print({cl_num: curr_clusters[cl_num] for cl_num in unmatched_clusters})\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['significant safety', 'significant investment']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflib.get_close_matches('significant adverse regulatory', next_keys.keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
